{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I merge the detected fire centroids into the fire perimeter boundary shapefiles, I end up with more observations than I started with (even doing a left join on the centroids), which suggests that there are some fire centroids that are matching on to multiple fire perimeters. I need to figure out why so that I can then decide what to do about it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First we need to merge on the perimeter boundary files, and then figure out which detected\n",
    "# fire centroids have merged on in mutiple places. In the detected fire data, a unique \n",
    "# index is (lat, long, date, gmt, src). We'll start with 2013. \n",
    "conn = psycopg2.connect('dbname=forest_fires')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('''CREATE TABLE merged_2013 AS\n",
    "             (SELECT points.*, polys.fire_name, polys.fire, polys.agency, polys.unit_id\n",
    "             FROM detected_fires_2013 as points\n",
    "                    LEFT JOIN daily_fire_shapefiles_2013 as polys\n",
    "             ON points.date = polys.date_ \n",
    "                AND ST_WITHIN(points.wkb_geometry, polys.wkb_geometry));\n",
    "            ''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected_fires_2013 obs:  184425\n",
      "Merged_2013 obs:  207404\n"
     ]
    }
   ],
   "source": [
    "# Just to display what I'm talking about: \n",
    "cursor.execute('''SELECT COUNT(*)\n",
    "                FROM detected_fires_2013;''')\n",
    "print 'Detected_fires_2013 obs: ', cursor.fetchall()[0][0]\n",
    "\n",
    "cursor.execute('''SELECT COUNT(*)\n",
    "                FROM merged_2013;''')\n",
    "print 'Merged_2013 obs: ', cursor.fetchall()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6L,), (6L,), (6L,), (6L,), (6L,), (6L,), (6L,), (6L,), (6L,), (6L,)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check if any obs. now have more than one row per (lat, long, date, gmt, and src), which\n",
    "# prior to this merge was unique. \n",
    "cursor.execute('''SELECT COUNT(*) as totals\n",
    "                FROM merged_2013\n",
    "                GROUP BY lat, long, date, gmt, src\n",
    "                ORDER BY totals DESC\n",
    "                LIMIT 10;''')\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, cool this is exactly what I thought. Let's get the (lat, long, date, gmt, src) of some \n",
    "of these obs and checkout what is going on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor.execute('''WITH totals_table AS \n",
    "                (SELECT COUNT(*) as totals, lat, long, date, gmt, src\n",
    "                FROM merged_2013\n",
    "                GROUP BY lat, long, date, gmt, src)\n",
    "                \n",
    "                SELECT lat, long, date, gmt, src \n",
    "                FROM totals_table \n",
    "                WHERE totals > 1;''')\n",
    "duplicates_list = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's just go down the above list and figure out what is going on. \n",
    "duplicates_info = []\n",
    "for duplicate in duplicates_list[:20]: \n",
    "    lat_coord, long_coord, date1, gmt, src = duplicate\n",
    "    \n",
    "    cursor.execute('''SELECT fire_name, fire, unit_id, agency\n",
    "                    FROM merged_2013\n",
    "                    WHERE lat = {} and long = {}\n",
    "                        and gmt = {} and date = '{}'\n",
    "                        and src = '{}'; '''.format(lat_coord, long_coord, gmt, date1, src))\n",
    "    duplicates_info.append([cursor.fetchall(), duplicate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "[('Rim', None, 'CA-STF', 'USFS'), ('Rim', None, 'CA-STF', 'USFS'), ('Rim', None, 'CA-STF', 'USFS')]\n",
      "\n",
      "\n",
      "\n",
      "(Decimal('38.015'), Decimal('-119.955'), datetime.date(2013, 8, 26), Decimal('2101'), 'ssec')\n",
      "--------------------------------------------------\n",
      "[('Lake', None, 'ID-NPF', 'USFS'), ('Lake Complex', None, 'ID-NPF', 'USFS')]\n",
      "\n",
      "\n",
      "\n",
      "(Decimal('45.569'), Decimal('-114.981'), datetime.date(2013, 8, 18), Decimal('1835'), 'gsfc')\n",
      "--------------------------------------------------\n",
      "[('Aspen', None, 'CA-SNF', 'USFS'), ('Aspen', None, 'CA-SNF', 'USFS')]\n",
      "\n",
      "\n",
      "\n",
      "(Decimal('37.317'), Decimal('-119.279'), datetime.date(2013, 7, 26), Decimal('626'), 'rsac')\n",
      "--------------------------------------------------\n",
      "[('Tres Lagunas', None, 'NM-N4S', 'State Agency'), ('Tres Lagunas', None, 'NM-N4S', 'State Agency'), ('Tres Lagunas', None, 'NM-N4S', 'State Agency')]\n",
      "\n",
      "\n",
      "\n",
      "(Decimal('35.711'), Decimal('-105.635'), datetime.date(2013, 6, 1), Decimal('442'), 'rsac')\n",
      "--------------------------------------------------\n",
      "[('Rim', None, 'CA-STF', 'USFS'), ('Rim', None, 'CA-STF', 'USFS'), ('Rim', None, 'CA-STF', 'USFS')]\n",
      "\n",
      "\n",
      "\n",
      "(Decimal('37.977'), Decimal('-119.826'), datetime.date(2013, 8, 26), Decimal('543'), 'ssec')\n",
      "--------------------------------------------------\n",
      "[('American', None, 'CA-TNF', 'USFS'), ('American', None, 'CA-TNF', 'USFS'), ('American', None, 'CA-TNF', 'USFS')]\n",
      "\n",
      "\n",
      "\n",
      "(Decimal('39.102'), Decimal('-120.544'), datetime.date(2013, 8, 26), Decimal('1000'), 'gsfc')\n",
      "--------------------------------------------------\n",
      "[('Rim', None, 'CA-STF', 'USFS'), ('Rim', None, 'CA-STF', 'USFS'), ('Rim', None, 'CA-STF', 'USFS')]\n",
      "\n",
      "\n",
      "\n",
      "(Decimal('38.020'), Decimal('-119.979'), datetime.date(2013, 8, 26), Decimal('2102'), 'rsac')\n",
      "--------------------------------------------------\n",
      "[('Rim', None, 'CA-STF', 'USFS'), ('Rim', None, 'CA-STF', 'USFS'), ('Rim', None, 'CA-STF', 'USFS')]\n",
      "\n",
      "\n",
      "\n",
      "(Decimal('37.926'), Decimal('-119.748'), datetime.date(2013, 8, 28), Decimal('944'), 'rsac')\n",
      "--------------------------------------------------\n",
      "[('Lodgepole', None, 'ID-SCF', 'USFS'), ('Lodgepole', None, 'ID-SCF', 'USFS')]\n",
      "\n",
      "\n",
      "\n",
      "(Decimal('44.549'), Decimal('-114.426'), datetime.date(2013, 7, 26), Decimal('1825'), 'rsac')\n",
      "--------------------------------------------------\n",
      "[('Lodgepole', None, 'ID-SCF', 'USFS'), ('Lodgepole', None, 'ID-SCF', 'USFS')]\n",
      "\n",
      "\n",
      "\n",
      "(Decimal('44.528'), Decimal('-114.473'), datetime.date(2013, 7, 30), Decimal('601'), 'rsac')\n"
     ]
    }
   ],
   "source": [
    "for duplicate in duplicates_info[:10]: \n",
    "    print '-' * 50 \n",
    "    print duplicate[0]\n",
    "    print '\\n' * 2\n",
    "    print duplicate[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From the above, it doesn't look like I'll be able to tell too much, with the exception of how many perimeter boundaries that given (lat, long, date, gmt, src) merged onto. I think to solve this definitively, I need to graph some of the above boundaries and see how/if they overlap (I assume they must overlap, or else I wouldn't be having this issue). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
