{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three things that I want to check out here. The previous eda files have more or less been playing around \n",
    "with less clear purposes. \n",
    "\n",
    "1.) How does this data look - after contacting the forest services, I've been told that each row should be a fire\n",
    "dectected, and there should be four pictures for every long/lat. pair, correspond to 4 pictures in that given day. \n",
    "I need to verify that, and if it is true see how far back that works. \n",
    "\n",
    "2.) How does the confidence level range across fires in general, and then how about across the 4 pictures per day? Is there a good range of fire confidence level from 10-90%?\n",
    "\n",
    "3.) How am I going to group these fires from day to day - do I go out 0.01 degrees in each lat/long direction, 0.10 \n",
    "degrees, etc.? To look into this what I'm going to do is just cycle through a bunch of different values and see how many fires pop up within that many degrees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def row_examination(df):\n",
    "    counts = df.groupby(['LAT', 'LONG', 'year', 'month', 'day']).count()\n",
    "    print 'Max. number of rows per lat/long coordinate: ', counts.max()[0]\n",
    "    print 'Min. number of rows per lat/long coordinate: ', counts.min()[0]\n",
    "    print 'Mean number of rows per lat/long coordinate: ', counts.mean()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conf_levels_examination(df): \n",
    "    print 'Confidence level info: ', df['CONF'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:  2015\n",
      "-------------------------------------------------- \n",
      "\n",
      "Max. number of rows per lat/long coordinate:  10\n",
      "Min. number of rows per lat/long coordinate:  1\n",
      "Mean number of rows per lat/long coordinate:  2.05243429241\n",
      "Confidence level info:  count    140171.000000\n",
      "mean         66.610961\n",
      "std          22.428298\n",
      "min           0.000000\n",
      "25%          52.000000\n",
      "50%          67.000000\n",
      "75%          84.000000\n",
      "max         100.000000\n",
      "Name: CONF, dtype: float64\n",
      "Year:  2014\n",
      "-------------------------------------------------- \n",
      "\n",
      "Max. number of rows per lat/long coordinate:  7\n",
      "Min. number of rows per lat/long coordinate:  1\n",
      "Mean number of rows per lat/long coordinate:  2.07766551185\n",
      "Confidence level info:  count    229688.000000\n",
      "mean         68.196545\n",
      "std          21.343116\n",
      "min           0.000000\n",
      "25%          55.000000\n",
      "50%          70.000000\n",
      "75%          84.000000\n",
      "max         100.000000\n",
      "Name: CONF, dtype: float64\n",
      "Year:  2013\n",
      "-------------------------------------------------- \n",
      "\n",
      "Max. number of rows per lat/long coordinate:  8\n",
      "Min. number of rows per lat/long coordinate:  1\n",
      "Mean number of rows per lat/long coordinate:  2.22563477505\n",
      "Confidence level info:  count    184425.000000\n",
      "mean         70.301510\n",
      "std          22.424611\n",
      "min           0.000000\n",
      "25%          55.000000\n",
      "50%          72.000000\n",
      "75%          89.000000\n",
      "max         100.000000\n",
      "Name: CONF, dtype: float64\n",
      "Year:  2012\n",
      "-------------------------------------------------- \n",
      "\n",
      "Max. number of rows per lat/long coordinate:  8\n",
      "Min. number of rows per lat/long coordinate:  1\n",
      "Mean number of rows per lat/long coordinate:  1.7068337176\n",
      "Confidence level info:  count    252439.000000\n",
      "mean         73.482013\n",
      "std          23.562693\n",
      "min           0.000000\n",
      "25%          58.000000\n",
      "50%          77.000000\n",
      "75%          95.000000\n",
      "max         100.000000\n",
      "Name: CONF, dtype: float64\n",
      "Year:  2011\n",
      "-------------------------------------------------- \n",
      "\n",
      "Max. number of rows per lat/long coordinate:  7\n",
      "Min. number of rows per lat/long coordinate:  1\n",
      "Mean number of rows per lat/long coordinate:  1.5921017095\n",
      "Confidence level info:  count    159164.000000\n",
      "mean         71.771041\n",
      "std          21.999171\n",
      "min           0.000000\n",
      "25%          58.000000\n",
      "50%          74.000000\n",
      "75%          90.000000\n",
      "max         100.000000\n",
      "Name: CONF, dtype: float64\n",
      "Year:  2010\n",
      "-------------------------------------------------- \n",
      "\n",
      "Max. number of rows per lat/long coordinate:  6\n",
      "Min. number of rows per lat/long coordinate:  1\n",
      "Mean number of rows per lat/long coordinate:  2.02070056358\n",
      "Confidence level info:  count    131586.000000\n",
      "mean         68.515108\n",
      "std          19.981432\n",
      "min           0.000000\n",
      "25%          56.000000\n",
      "50%          70.000000\n",
      "75%          83.000000\n",
      "max         100.000000\n",
      "Name: CONF, dtype: float64\n",
      "Year:  2009\n",
      "-------------------------------------------------- \n",
      "\n",
      "Max. number of rows per lat/long coordinate:  6\n",
      "Min. number of rows per lat/long coordinate:  1\n",
      "Mean number of rows per lat/long coordinate:  2.02131120488\n",
      "Confidence level info:  count    171484.000000\n",
      "mean         68.954025\n",
      "std          21.204471\n",
      "min           0.000000\n",
      "25%          55.000000\n",
      "50%          71.000000\n",
      "75%          85.000000\n",
      "max         100.000000\n",
      "Name: CONF, dtype: float64\n",
      "Year:  2008\n",
      "-------------------------------------------------- \n",
      "\n",
      "Max. number of rows per lat/long coordinate:  2\n",
      "Min. number of rows per lat/long coordinate:  1\n",
      "Mean number of rows per lat/long coordinate:  1.00093257484\n",
      "Confidence level info:  count    85864.000000\n",
      "mean        69.652707\n",
      "std         22.010853\n",
      "min          0.000000\n",
      "25%         55.000000\n",
      "50%         72.000000\n",
      "75%         87.000000\n",
      "max        100.000000\n",
      "Name: CONF, dtype: float64\n",
      "Year:  2007\n",
      "-------------------------------------------------- \n",
      "\n",
      "Max. number of rows per lat/long coordinate:  2\n",
      "Min. number of rows per lat/long coordinate:  1\n",
      "Mean number of rows per lat/long coordinate:  1.00114131665\n",
      "Confidence level info:  count    101753.000000\n",
      "mean         71.766228\n",
      "std          22.950290\n",
      "min           0.000000\n",
      "25%          57.000000\n",
      "50%          74.000000\n",
      "75%          92.000000\n",
      "max         100.000000\n",
      "Name: CONF, dtype: float64\n",
      "Year:  2006\n",
      "-------------------------------------------------- \n",
      "\n",
      "Max. number of rows per lat/long coordinate:  3\n",
      "Min. number of rows per lat/long coordinate:  1\n",
      "Mean number of rows per lat/long coordinate:  1.00112784013\n",
      "Confidence level info:  count    91428.000000\n",
      "mean        71.065724\n",
      "std         22.361650\n",
      "min          0.000000\n",
      "25%         56.000000\n",
      "50%         73.000000\n",
      "75%         90.000000\n",
      "max        100.000000\n",
      "Name: CONF, dtype: float64\n",
      "Year:  2005\n",
      "-------------------------------------------------- \n",
      "\n",
      "Max. number of rows per lat/long coordinate:  2\n",
      "Min. number of rows per lat/long coordinate:  1\n",
      "Mean number of rows per lat/long coordinate:  1.00068304216\n",
      "Confidence level info:  count    76182.000000\n",
      "mean        68.887624\n",
      "std         21.135899\n",
      "min          0.000000\n",
      "25%         55.000000\n",
      "50%         71.000000\n",
      "75%         85.000000\n",
      "max        100.000000\n",
      "Name: CONF, dtype: float64\n",
      "Year:  2004\n",
      "-------------------------------------------------- \n",
      "\n",
      "Max. number of rows per lat/long coordinate:  2\n",
      "Min. number of rows per lat/long coordinate:  1\n",
      "Mean number of rows per lat/long coordinate:  1.00060698554\n",
      "Confidence level info:  count    57697.000000\n",
      "mean        68.253150\n",
      "std         21.299174\n",
      "min          0.000000\n",
      "25%         55.000000\n",
      "50%         70.000000\n",
      "75%         84.000000\n",
      "max        100.000000\n",
      "Name: CONF, dtype: float64\n",
      "Year:  2003\n",
      "-------------------------------------------------- \n",
      "\n",
      "Max. number of rows per lat/long coordinate:  2\n",
      "Min. number of rows per lat/long coordinate:  1\n",
      "Mean number of rows per lat/long coordinate:  1.00131260711\n",
      "Confidence level info:  count    82387.00000\n",
      "mean        70.49032\n",
      "std         22.46276\n",
      "min          0.00000\n",
      "25%         56.00000\n",
      "50%         73.00000\n",
      "75%         89.00000\n",
      "max        100.00000\n",
      "Name: CONF, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for year in xrange(2015, 2002, -1): \n",
    "    with open('../../../data/pickled_data/MODIS/df_' + str(year) + '.pkl') as f: \n",
    "        df = pickle.load(f)\n",
    "        print 'Year: ', str(year)\n",
    "        print '-' * 50, '\\n'\n",
    "        row_examination(df)\n",
    "        conf_levels_examination(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, I can see that starting in 2009 it looks like the 4 pictures per lat/long coordinates might be true, but before that it doesn't look to be true. So now I need to just pull out some rows and see exactly what is going on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def examine_index(df, index): \n",
    "    print df.query('LAT == @index[0] & LONG == @index[1] & year == @index[2] & month == @index[3] & day == @index[4]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def examine_lown_rows(df, count_num, output = False): \n",
    "    fires_counts = df.groupby(['LAT', 'LONG', 'year', 'month', 'day']).count()['AREA'] == count_num\n",
    "    if output: \n",
    "        for index in fires_counts[fires_counts == True].index[0:10]:\n",
    "            print '-' * 50\n",
    "            examine_index(df, index)\n",
    "    else:  \n",
    "        return fires_counts.index[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "                        AREA             PERIMETER   FIRE_  FIRE_ID  \\\n",
      "140169  0.0000000000000E+000  0.0000000000000E+000  140170   133875   \n",
      "140170  0.0000000000000E+000  0.0000000000000E+000  140171   564951   \n",
      "\n",
      "                  LAT           LONG  JULIAN   GMT   TEMP  SPIX  TPIX SAT_SRC  \\\n",
      "140169  2.517000E+001  -8.09690E+001     108  1835  312.9   1.1   1.1       A   \n",
      "140170  2.517000E+001  -8.09690E+001     108  1835  312.9   1.1   1.1       A   \n",
      "\n",
      "        CONF  FRP  year  month  day  \n",
      "140169    47  6.3  2015      4   18  \n",
      "140170    47  6.3  2015      4   18  \n",
      "--------------------------------------------------\n",
      "                        AREA             PERIMETER   FIRE_  FIRE_ID  \\\n",
      "140167  0.0000000000000E+000  0.0000000000000E+000  140168   133876   \n",
      "140168  0.0000000000000E+000  0.0000000000000E+000  140169   564952   \n",
      "\n",
      "                  LAT           LONG  JULIAN   GMT   TEMP  SPIX  TPIX SAT_SRC  \\\n",
      "140167  2.517200E+001  -8.09580E+001     108  1831  312.8   1.1   1.1       A   \n",
      "140168  2.517200E+001  -8.09580E+001     108  1831  312.8   1.1   1.1       A   \n",
      "\n",
      "        CONF  FRP  year  month  day  \n",
      "140167    35  6.1  2015      4   18  \n",
      "140168    35  6.1  2015      4   18  \n",
      "--------------------------------------------------\n",
      "                        AREA             PERIMETER   FIRE_  FIRE_ID  \\\n",
      "140165  0.0000000000000E+000  0.0000000000000E+000  140166   166849   \n",
      "140166  0.0000000000000E+000  0.0000000000000E+000  140167   597925   \n",
      "\n",
      "                  LAT           LONG  JULIAN   GMT   TEMP  SPIX  TPIX SAT_SRC  \\\n",
      "140165  2.517700E+001  -8.06590E+001     149  1825  310.6   1.3   1.1       A   \n",
      "140166  2.517700E+001  -8.06590E+001     149  1825  310.6   1.3   1.1       A   \n",
      "\n",
      "        CONF  FRP  year  month  day  \n",
      "140165     0  5.2  2015      5   29  \n",
      "140166     0  5.2  2015      5   29  \n",
      "--------------------------------------------------\n",
      "                        AREA             PERIMETER   FIRE_  FIRE_ID  \\\n",
      "140163  0.0000000000000E+000  0.0000000000000E+000  140164   255574   \n",
      "140164  0.0000000000000E+000  0.0000000000000E+000  140165   686650   \n",
      "\n",
      "                  LAT           LONG  JULIAN   GMT   TEMP  SPIX  TPIX SAT_SRC  \\\n",
      "140163  2.518500E+001  -8.09140E+001     195  1836  315.4     1     1       A   \n",
      "140164  2.518500E+001  -8.09140E+001     195  1836  315.4     1     1       A   \n",
      "\n",
      "        CONF  FRP  year  month  day  \n",
      "140163    42  6.9  2015      7   14  \n",
      "140164    42  6.9  2015      7   14  \n",
      "--------------------------------------------------\n",
      "                        AREA             PERIMETER   FIRE_  FIRE_ID  \\\n",
      "140161  0.0000000000000E+000  0.0000000000000E+000  140162   373017   \n",
      "140162  0.0000000000000E+000  0.0000000000000E+000  140163   805533   \n",
      "\n",
      "                  LAT           LONG  JULIAN   GMT   TEMP  SPIX  TPIX SAT_SRC  \\\n",
      "140161  2.520000E+001  -8.07360E+001     139  1608  314.8   1.2   1.1       T   \n",
      "140162  2.520000E+001  -8.07360E+001     139  1608  314.8   1.2   1.1       T   \n",
      "\n",
      "        CONF  FRP  year  month  day  \n",
      "140161    33  9.9  2015      5   19  \n",
      "140162    33  9.9  2015      5   19  \n",
      "--------------------------------------------------\n",
      "                        AREA             PERIMETER   FIRE_  FIRE_ID  \\\n",
      "140159  0.0000000000000E+000  0.0000000000000E+000  140160   373018   \n",
      "140160  0.0000000000000E+000  0.0000000000000E+000  140161   805534   \n",
      "\n",
      "                  LAT           LONG  JULIAN   GMT   TEMP  SPIX  TPIX SAT_SRC  \\\n",
      "140159  2.520600E+001  -8.07720E+001     139  1608  313.3   1.2   1.1       T   \n",
      "140160  2.520600E+001  -8.07720E+001     139  1608  313.3   1.2   1.1       T   \n",
      "\n",
      "        CONF  FRP  year  month  day  \n",
      "140159    44  8.1  2015      5   19  \n",
      "140160    44  8.1  2015      5   19  \n",
      "--------------------------------------------------\n",
      "                        AREA             PERIMETER   FIRE_  FIRE_ID  \\\n",
      "140157  0.0000000000000E+000  0.0000000000000E+000  140158   118315   \n",
      "140158  0.0000000000000E+000  0.0000000000000E+000  140159   549391   \n",
      "\n",
      "                  LAT           LONG  JULIAN   GMT   TEMP  SPIX  TPIX SAT_SRC  \\\n",
      "140157  2.548600E+001  -8.03730E+001      89  1805  313.2   3.2   1.7       A   \n",
      "140158  2.548600E+001  -8.03730E+001      89  1805  313.2   3.2   1.7       A   \n",
      "\n",
      "        CONF   FRP  year  month  day  \n",
      "140157    32  55.7  2015      3   30  \n",
      "140158    32  55.7  2015      3   30  \n",
      "--------------------------------------------------\n",
      "                        AREA             PERIMETER   FIRE_  FIRE_ID  \\\n",
      "140155  0.0000000000000E+000  0.0000000000000E+000  140156   151086   \n",
      "140156  0.0000000000000E+000  0.0000000000000E+000  140157   582162   \n",
      "\n",
      "                  LAT           LONG  JULIAN   GMT   TEMP  SPIX  TPIX SAT_SRC  \\\n",
      "140155  2.551200E+001  -9.75740E+001     128  1949  315.3     1     1       A   \n",
      "140156  2.551200E+001  -9.75740E+001     128  1949  315.3     1     1       A   \n",
      "\n",
      "        CONF  FRP  year  month  day  \n",
      "140155    32  6.1  2015      5    8  \n",
      "140156    32  6.1  2015      5    8  \n",
      "--------------------------------------------------\n",
      "                        AREA             PERIMETER   FIRE_  FIRE_ID  \\\n",
      "140153  0.0000000000000E+000  0.0000000000000E+000  140154    91408   \n",
      "140154  0.0000000000000E+000  0.0000000000000E+000  140155   522484   \n",
      "\n",
      "                  LAT           LONG  JULIAN   GMT   TEMP  SPIX  TPIX SAT_SRC  \\\n",
      "140153  2.552100E+001  -8.05430E+001      28  1833  322.2   1.1     1       A   \n",
      "140154  2.552100E+001  -8.05430E+001      28  1833  322.2   1.1     1       A   \n",
      "\n",
      "        CONF   FRP  year  month  day  \n",
      "140153    81  18.8  2015      1   28  \n",
      "140154    81  18.8  2015      1   28  \n",
      "--------------------------------------------------\n",
      "                        AREA             PERIMETER   FIRE_  FIRE_ID  \\\n",
      "140151  0.0000000000000E+000  0.0000000000000E+000  140152   258995   \n",
      "140152  0.0000000000000E+000  0.0000000000000E+000  140153   690071   \n",
      "\n",
      "                  LAT           LONG  JULIAN   GMT   TEMP  SPIX  TPIX SAT_SRC  \\\n",
      "140151  2.556000E+001  -9.77710E+001     204  2013  326.2   1.8   1.3       A   \n",
      "140152  2.556000E+001  -9.77710E+001     204  2013  326.2   1.8   1.3       A   \n",
      "\n",
      "        CONF   FRP  year  month  day  \n",
      "140151    60  23.5  2015      7   23  \n",
      "140152    60  23.5  2015      7   23  \n"
     ]
    }
   ],
   "source": [
    "for year in xrange(2015, 2014, -1): \n",
    "    with open('../../../data/pickled_data/MODIS/df_' + str(year) + '.pkl') as f: \n",
    "        df = pickle.load(f)\n",
    "        examine_lown_rows(df, 2, True)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My hunch is that for those obs. where there are only 1 or 2 obs. for a given lat/long/date combination, it's because \n",
    "the fire moved quickly and so the lat/long coordinates changed quickly. The way to check this would be to see if there are larger number of fires (rows) within a given lat/long distance from that current long/lat distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Number 2\n",
      "--------------------------------------------------\n",
      "dist 0.001\n",
      "--------------------------------------------------\n",
      "2 2.517000E+001 -8.09690E+001\n",
      "2 2.517200E+001 -8.09580E+001\n",
      "2 2.517700E+001 -8.06590E+001\n",
      "2 2.518500E+001 -8.09140E+001\n",
      "2 2.520000E+001 -8.07360E+001\n",
      "2 2.520600E+001 -8.07720E+001\n",
      "2 2.548600E+001 -8.03730E+001\n",
      "2 2.551200E+001 -9.75740E+001\n",
      "2 2.552100E+001 -8.05430E+001\n",
      "2 2.556000E+001 -9.77710E+001\n",
      "dist 0.01\n",
      "--------------------------------------------------\n",
      "2 2.517000E+001 -8.09690E+001\n",
      "2 2.517200E+001 -8.09580E+001\n",
      "2 2.517700E+001 -8.06590E+001\n",
      "2 2.518500E+001 -8.09140E+001\n",
      "2 2.520000E+001 -8.07360E+001\n",
      "2 2.520600E+001 -8.07720E+001\n",
      "2 2.548600E+001 -8.03730E+001\n",
      "2 2.551200E+001 -9.75740E+001\n",
      "2 2.552100E+001 -8.05430E+001\n",
      "4 2.556000E+001 -9.77710E+001\n",
      "dist 0.05\n",
      "--------------------------------------------------\n",
      "4 2.517000E+001 -8.09690E+001\n",
      "6 2.517200E+001 -8.09580E+001\n",
      "2 2.517700E+001 -8.06590E+001\n",
      "4 2.518500E+001 -8.09140E+001\n",
      "4 2.520000E+001 -8.07360E+001\n",
      "4 2.520600E+001 -8.07720E+001\n",
      "2 2.548600E+001 -8.03730E+001\n",
      "2 2.551200E+001 -9.75740E+001\n",
      "2 2.552100E+001 -8.05430E+001\n",
      "6 2.556000E+001 -9.77710E+001\n",
      "dist 0.1\n",
      "--------------------------------------------------\n",
      "6 2.517000E+001 -8.09690E+001\n",
      "6 2.517200E+001 -8.09580E+001\n",
      "4 2.517700E+001 -8.06590E+001\n",
      "6 2.518500E+001 -8.09140E+001\n",
      "6 2.520000E+001 -8.07360E+001\n",
      "4 2.520600E+001 -8.07720E+001\n",
      "2 2.548600E+001 -8.03730E+001\n",
      "2 2.551200E+001 -9.75740E+001\n",
      "2 2.552100E+001 -8.05430E+001\n",
      "9 2.556000E+001 -9.77710E+001\n",
      "Row Number 4\n",
      "--------------------------------------------------\n",
      "dist 0.001\n",
      "--------------------------------------------------\n",
      "2 25.17 -80.969\n",
      "2 25.172 -80.958\n",
      "2 25.177 -80.659\n",
      "2 25.185 -80.914\n",
      "2 25.2 -80.736\n",
      "2 25.206 -80.772\n",
      "2 25.486 -80.373\n",
      "2 25.512 -97.574\n",
      "2 25.521 -80.543\n",
      "2 25.56 -97.771\n",
      "dist 0.01\n",
      "--------------------------------------------------\n",
      "2 25.17 -80.969\n",
      "2 25.172 -80.958\n",
      "2 25.177 -80.659\n",
      "2 25.185 -80.914\n",
      "2 25.2 -80.736\n",
      "2 25.206 -80.772\n",
      "2 25.486 -80.373\n",
      "2 25.512 -97.574\n",
      "2 25.521 -80.543\n",
      "4 25.56 -97.771\n",
      "dist 0.05\n",
      "--------------------------------------------------\n",
      "4 25.17 -80.969\n",
      "6 25.172 -80.958\n",
      "2 25.177 -80.659\n",
      "4 25.185 -80.914\n",
      "4 25.2 -80.736\n",
      "4 25.206 -80.772\n",
      "2 25.486 -80.373\n",
      "2 25.512 -97.574\n",
      "2 25.521 -80.543\n",
      "6 25.56 -97.771\n",
      "dist 0.1\n",
      "--------------------------------------------------\n",
      "6 25.17 -80.969\n",
      "6 25.172 -80.958\n",
      "4 25.177 -80.659\n",
      "6 25.185 -80.914\n",
      "6 25.2 -80.736\n",
      "4 25.206 -80.772\n",
      "2 25.486 -80.373\n",
      "2 25.512 -97.574\n",
      "2 25.521 -80.543\n",
      "9 25.56 -97.771\n",
      "Row Number 10\n",
      "--------------------------------------------------\n",
      "dist 0.001\n",
      "--------------------------------------------------\n",
      "2 25.17 -80.969\n",
      "2 25.172 -80.958\n",
      "2 25.177 -80.659\n",
      "2 25.185 -80.914\n",
      "2 25.2 -80.736\n",
      "2 25.206 -80.772\n",
      "2 25.486 -80.373\n",
      "2 25.512 -97.574\n",
      "2 25.521 -80.543\n",
      "2 25.56 -97.771\n",
      "dist 0.01\n",
      "--------------------------------------------------\n",
      "2 25.17 -80.969\n",
      "2 25.172 -80.958\n",
      "2 25.177 -80.659\n",
      "2 25.185 -80.914\n",
      "2 25.2 -80.736\n",
      "2 25.206 -80.772\n",
      "2 25.486 -80.373\n",
      "2 25.512 -97.574\n",
      "2 25.521 -80.543\n",
      "4 25.56 -97.771\n",
      "dist 0.05\n",
      "--------------------------------------------------\n",
      "4 25.17 -80.969\n",
      "6 25.172 -80.958\n",
      "2 25.177 -80.659\n",
      "4 25.185 -80.914\n",
      "4 25.2 -80.736\n",
      "4 25.206 -80.772\n",
      "2 25.486 -80.373\n",
      "2 25.512 -97.574\n",
      "2 25.521 -80.543\n",
      "6 25.56 -97.771\n",
      "dist 0.1\n",
      "--------------------------------------------------\n",
      "6 25.17 -80.969\n",
      "6 25.172 -80.958\n",
      "4 25.177 -80.659\n",
      "6 25.185 -80.914\n",
      "6 25.2 -80.736\n",
      "4 25.206 -80.772\n",
      "2 25.486 -80.373\n",
      "2 25.512 -97.574\n",
      "2 25.521 -80.543\n",
      "9 25.56 -97.771\n"
     ]
    }
   ],
   "source": [
    "for year in xrange(2015, 2014, -1): \n",
    "    with open('../../../data/pickled_data/MODIS/df_' + str(year) + '.pkl') as f: \n",
    "        df = pickle.load(f)\n",
    "        for row_number in [2, 4, 10]: \n",
    "            print 'Row Number', str(row_number)\n",
    "            print '-' * 50\n",
    "            rows_less = examine_lown_rows(df, row_number, False)\n",
    "            df['LAT'] = df['LAT'].astype(float)\n",
    "            df['LONG'] = df['LONG'].astype(float)\n",
    "            for dist_out in [0.001, 0.01, 0.05, 0.1]:\n",
    "                print 'dist', str(dist_out)\n",
    "                print '-' * 50\n",
    "                for index in rows_less: \n",
    "                    lat_1, lat_2 = float(index[0]) - dist_out, float(index[0]) + dist_out\n",
    "                    long_1, long_2 = float(index[1]) - dist_out, float(index[1]) + dist_out\n",
    "                    result = df.query('LAT > @lat_1 & LAT < @lat_2 & LONG > @long_1 & LONG < @long_2')\n",
    "                    print result.shape[0], index[0], index[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The above doesn't seem to support my hypothesis (but I did only look at 10 obs). Maybe it's just that those fires aren't actually present at those locations later in the day, and so there aren't pictures for them. Ultimately, the way to represent a square kilometer is by +/- 0.01 degrees, so I need to stick with that. What I need to do now is to find some large fire in a given year and try to track that, and see how likely it is that I can track a particular fire (i.e. are there 4 pics. a day for that fire, are there 4 pics. a day for multiple days for that fire, etc.). What does this data loe)ok like for a location where I know there was a large fire that burned for a very long period of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If I go to the following website (https://www.nifc.gov/fireInfo/fireInfo_stats_lgFires.html), I can pick some large fires that are from 2009+ (since earlier I decided to only look past this data). I'll start off by looking at some 2012 fires, and figure out if I got out a certain distance from that fire's origin, how many rows there are in the data (i.e. how many detected fires that far out from the large fires origin). I'll look at the Long Draw fire (42.392, -117.894), the Holloway fire (41.973, -118.366), the Mustang Complex (45.425, -114.59), Rush (40.621   , -120.152), and Ash Creek MT (45.669, -106.469). We'll check these out first.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fires = [('Long Draw', 42.392, -117.894), ('Holloway', 41.973, -118.366), ('Mustang Complex', 45.425, -114.59), \n",
    "        ('Rush', 40.621, -120.152), ('Ash Creek MT', 45.669, -106.469)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long Draw\n",
      "--------------------------------------------------\n",
      "Dist_out: 0.001 0 \n",
      "\n",
      "Dist_out: 0.01 10 \n",
      "\n",
      "Dist_out: 0.1 610 \n",
      "\n",
      "Dist_out: 0.2 1827 \n",
      "\n",
      "Dist_out: 0.3 3106 \n",
      "\n",
      "Dist_out: 0.4 4431 \n",
      "\n",
      "Dist_out: 0.5 6049 \n",
      "\n",
      "Holloway\n",
      "--------------------------------------------------\n",
      "Dist_out: 0.001 0 \n",
      "\n",
      "Dist_out: 0.01 15 \n",
      "\n",
      "Dist_out: 0.1 1152 \n",
      "\n",
      "Dist_out: 0.2 3288 \n",
      "\n",
      "Dist_out: 0.3 4541 \n",
      "\n",
      "Dist_out: 0.4 5657 \n",
      "\n",
      "Dist_out: 0.5 6159 \n",
      "\n",
      "Mustang Complex\n",
      "--------------------------------------------------\n",
      "Dist_out: 0.001 0 \n",
      "\n",
      "Dist_out: 0.01 30 \n",
      "\n",
      "Dist_out: 0.1 2292 \n",
      "\n",
      "Dist_out: 0.2 5718 \n",
      "\n",
      "Dist_out: 0.3 8174 \n",
      "\n",
      "Dist_out: 0.4 11735 \n",
      "\n",
      "Dist_out: 0.5 14212 \n",
      "\n",
      "Rush\n",
      "--------------------------------------------------\n",
      "Dist_out: 0.001 0 \n",
      "\n",
      "Dist_out: 0.01 3 \n",
      "\n",
      "Dist_out: 0.1 424 \n",
      "\n",
      "Dist_out: 0.2 1375 \n",
      "\n",
      "Dist_out: 0.3 2425 \n",
      "\n",
      "Dist_out: 0.4 2465 \n",
      "\n",
      "Dist_out: 0.5 2525 \n",
      "\n",
      "Ash Creek MT\n",
      "--------------------------------------------------\n",
      "Dist_out: 0.001 0 \n",
      "\n",
      "Dist_out: 0.01 38 \n",
      "\n",
      "Dist_out: 0.1 602 \n",
      "\n",
      "Dist_out: 0.2 1377 \n",
      "\n",
      "Dist_out: 0.3 2337 \n",
      "\n",
      "Dist_out: 0.4 3536 \n",
      "\n",
      "Dist_out: 0.5 5769 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../../../data/pickled_data/MODIS/df_' + str(2012) + '.pkl') as f: \n",
    "    df = pickle.load(f)\n",
    "    df['LAT'] = df['LAT'].astype(float)\n",
    "    df['LONG'] = df['LONG'].astype(float)\n",
    "    for fire in fires: \n",
    "        print fire[0]\n",
    "        print '-' * 50\n",
    "        lat_orig, long_orig = fire[1], fire[2]\n",
    "        for dist_out in [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5]: \n",
    "            lat_1, lat_2 = lat_orig - dist_out, lat_orig + dist_out \n",
    "            long_1, long_2 = long_orig - dist_out, long_orig + dist_out\n",
    "            result = df.query('LAT > @lat_1 & LAT < @lat_2 & LONG > @long_1 & LONG < @long_2')\n",
    "            print 'Dist_out: %s' %str(dist_out), result.shape[0], '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks fairly legit, but what I want to do is take 100 unique random LAT/LONG pairs from the 2012 database, and \n",
    "look at the average number of obs. we get at dist_out of the above values (0.001, 0.01, 0.1, 0.2, 0.3, 0.4, and 0.5). If the number of observations that far out is on average the same as above, that would suggest that we weren't actually able to locate the Long Draw fire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with Rand\n"
     ]
    }
   ],
   "source": [
    "with open('../../../data/pickled_data/MODIS/df_' + str(2012) + '.pkl') as f: \n",
    "    df = pickle.load(f)\n",
    "    df['LAT'] = df['LAT'].astype(float)\n",
    "    df['LONG'] = df['LONG'].astype(float)\n",
    "    df = df.set_index(['LAT', 'LONG'])\n",
    "    indices = df.index\n",
    "    unique_indices = np.unique(indices)\n",
    "    num_indices = len(unique_indices)\n",
    "    obs_array = []\n",
    "    rand_indices = np.random.randint(low=0, high=num_indices, size=100)\n",
    "    for index in rand_indices: \n",
    "        lat_orig, long_orig = unique_indices[index]\n",
    "        num_obs = []\n",
    "        for dist_out in [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5]: \n",
    "            lat_1, lat_2 = lat_orig - dist_out, lat_orig + dist_out \n",
    "            long_1, long_2 = long_orig - dist_out, long_orig + dist_out\n",
    "            result = df.query('LAT > @lat_1 & LAT < @lat_2 & LONG > @long_1 & LONG < @long_2')\n",
    "            num_obs.append(result.shape[0])\n",
    "        obs_array.append(num_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.20000000e+00,   1.72300000e+01,   6.67580000e+02,\n",
       "         1.41051000e+03,   1.89278000e+03,   2.28991000e+03,\n",
       "         2.68952000e+03])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(obs_array).mean(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above seems to suggest that our results from attempting to look at the Long Draw fire are fairly successful, at least if we look out far enough. Up to 0.1 degrees, the numbers we were seeing for Long Draw seem to be roughly the same on average, whereas if we go 0.2 degrees +, we end up with a much larger number of obs. for the Long Draw fire. Now we'll try to look at the Railbelt Complex fire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
